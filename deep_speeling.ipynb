{
 "cells": [
  {
   "attachments": {
    "MarquisdeFavras.jpg": {
     "image/jpeg": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spelling Correction using Deep Learning\n",
    "\n",
    "Inspired by https://medium.com/@majortal/deep-spelling-9ffef96a24f6. Code can be found at https://github.com/MajorTal/DeepSpell/blob/master/keras_spell.py.\n",
    "\n",
    "**Character Sequence to Sequence** code pulled from https://github.com/mdcramer/deep-learning/tree/master/seq2seq.\n",
    "\n",
    "Environment initialization:\n",
    "* open Acaconda terminal\n",
    "* run \">activate tensorflow\"\n",
    "* run \">jupyter notebook\"\n",
    "\n",
    "\"I see that you have made three spelling mistakes.\" - Marquis de Favras, purportedly, upon the reading of his death warrant prior to be hanged in 1790.\n",
    "![MarquisdeFavras.jpg](attachment:MarquisdeFavras.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize global variables\n",
    "**Make sure to run this cell first each time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These filesname are loaded here since they're used after the graph has been saved\n",
    "GRAPH_PARAMETERS = \"graph_params\" # Filename for storing parameters associated with the graph\n",
    "SOURCE_INT_TO_LETTER = \"sourceinttoletter.json\" # Filename for storing INT to letter List for source sentences\n",
    "TARGET_INT_TO_LETTER = \"targetinttoletter.json\" # Filename for storing INT to letter List for target sentences\n",
    "SOURCE_LETTER_TO_INT = \"sourcelettertoint.json\" # Filename for storing letter to INT List for source sentences\n",
    "\n",
    "# This is where the graph is going to be saved and reloaded\n",
    "checkpoint = \"./best_model.ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Download raw data file from the internet and uncompress it\n",
    "\n",
    "[One Billion Word Benchmark for Measuring Progress in Statistical Language Modeling](https://research.google.com/pubs/pub41880.html)\n",
    "\n",
    "**Start here if you are going to work with the big dataset** The dataset lives in the /data/ folder.\n",
    "\n",
    "**Skip to below to work with the small dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local copy of compressed data file is up to date.\n",
      "Data file is already uncompressed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import errno\n",
    "import requests\n",
    "import gzip\n",
    "\n",
    "NEWS_FILE_NAME_COMPRESSED = os.path.join(os.path.expanduser(\"data\"), \"news.2013.en.shuffled.gz\") # 1.1 GB file\n",
    "DATA_FILES_URL = \"http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2013.en.shuffled.gz\" # file location\n",
    "\n",
    "# create directory for data, if it does not already exist\n",
    "try:\n",
    "    os.makedirs(os.path.dirname(NEWS_FILE_NAME_COMPRESSED))\n",
    "except OSError as exception:\n",
    "    if exception.errno != errno.EEXIST:\n",
    "        raise\n",
    "\n",
    "# check size of current data file\n",
    "try:\n",
    "    current_size = os.path.getsize(NEWS_FILE_NAME_COMPRESSED)\n",
    "except:\n",
    "    current_size = 0\n",
    "\n",
    "# check size of data file on internet\n",
    "response = requests.get(DATA_FILES_URL, stream=True)\n",
    "total_length = response.headers.get('content-length') # returns a str\n",
    "total_length = int(total_length)\n",
    "    \n",
    "# download file if it is larger than the one already in the data directory\n",
    "if (total_length > current_size):\n",
    "    print(\"Download compressed data file\")\n",
    "    with open(NEWS_FILE_NAME_COMPRESSED, \"wb\") as output_file: # open for writing in binary mode\n",
    "        downloaded = percentage = 0\n",
    "        print(\"»\"*100)\n",
    "        for data in response.iter_content(chunk_size=4096):\n",
    "            downloaded += len(data)\n",
    "            output_file.write(data)\n",
    "            new_percentage = 100 * downloaded // total_length # // is floor divide\n",
    "            if new_percentage > percentage:\n",
    "                print(\"o\", end=\"\") # end=\"\" remove carriage return\n",
    "                percentage = new_percentage\n",
    "    print() # add carriage return at the end of progress indicator\n",
    "else:\n",
    "    print(\"Local copy of compressed data file is up to date.\")\n",
    "    \n",
    "# uncompress data\n",
    "if (os.path.isfile(NEWS_FILE_NAME_COMPRESSED[:-3])): # check to see if file already exists\n",
    "    print(\"Data file is already uncompressed.\")\n",
    "else:\n",
    "    print(\"Uncompress data file.\") # uncompress the file if it does not\n",
    "    with gzip.open(NEWS_FILE_NAME_COMPRESSED, 'rb') as compressed_file:\n",
    "        with open(NEWS_FILE_NAME_COMPRESSED[:-3], 'wb') as outfile: #2.5 GB file\n",
    "            outfile.write(compressed_file.read())\n",
    "    print(\"Data file uncompressed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file is already clean.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "NEWS_FILE_NAME_CLEAN = os.path.join(os.path.expanduser(\"data\"), \"news.2013.en.clean\") # clean data file\n",
    "NEWS_FILE_NAME = os.path.join(os.path.expanduser(\"data\"), \"news.2013.en.shuffled\") # uncompressed data file\n",
    "\n",
    "NORMALIZE_WHITESPACE_REGEX = re.compile(r'[^\\S\\n]+', re.UNICODE) # match all whitespace except newlines\n",
    "RE_DASH_FILTER = re.compile(r'[\\-\\˗\\֊\\‐\\‑\\‒\\–\\—\\⁻\\₋\\−\\﹣\\－]', re.UNICODE)\n",
    "RE_APOSTROPHE_FILTER = re.compile(r'&#39;|[ʼ՚＇‘’‛❛❜ߴߵ`‵´ˊˋ{}{}{}{}{}{}{}{}{}]'\n",
    "                                  .format(chr(768), chr(769), chr(832), chr(833), chr(2387),\n",
    "                                          chr(5151), chr(5152), chr(65344), chr(8242)), re.UNICODE)\n",
    "RE_LEFT_PARENTH_FILTER = re.compile(r'[\\(\\[\\{\\⁽\\₍\\❨\\❪\\﹙\\（]', re.UNICODE)\n",
    "RE_RIGHT_PARENTH_FILTER = re.compile(r'[\\)\\]\\}\\⁾\\₎\\❩\\❫\\﹚\\）]', re.UNICODE)\n",
    "ALLOWED_CURRENCIES = \"\"\"¥£₪$€฿₨\"\"\"\n",
    "ALLOWED_PUNCTUATION = \"\"\"-!?/;\"'%&<>.()[]{}@#:,|=*\"\"\"\n",
    "RE_BASIC_CLEANER = re.compile(r'[^\\w\\s{}{}]'\n",
    "                              .format(re.escape(ALLOWED_CURRENCIES), re.escape(ALLOWED_PUNCTUATION)), re.UNICODE)\n",
    "\n",
    "def file_len(fname):\n",
    "    with open(fname, encoding=\"utf8\") as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1\n",
    "\n",
    "def clean_text(text):\n",
    "    # Clean the text - remove unwanted chars, fold punctuation etc.\n",
    "    result = NORMALIZE_WHITESPACE_REGEX.sub(' ', text.strip())\n",
    "    result = RE_DASH_FILTER.sub('-', result)\n",
    "    result = RE_APOSTROPHE_FILTER.sub(\"'\", result)\n",
    "    result = RE_LEFT_PARENTH_FILTER.sub(\"(\", result)\n",
    "    result = RE_RIGHT_PARENTH_FILTER.sub(\")\", result)\n",
    "    result = RE_BASIC_CLEANER.sub('', result)\n",
    "    return result\n",
    "\n",
    "if (os.path.isfile(NEWS_FILE_NAME_CLEAN)):\n",
    "    print(\"Data file is already clean.\")\n",
    "else:    \n",
    "    print(\"Clean data file:\")\n",
    "    number_lines = file_len(NEWS_FILE_NAME)\n",
    "    with open(NEWS_FILE_NAME_CLEAN, \"wb\") as clean_data:\n",
    "        processed = percentage = 0\n",
    "        for line in open(NEWS_FILE_NAME, encoding=\"utf8\"):\n",
    "            processed += 1\n",
    "            # decoded_line = line.decode('utf-8') # https://stackoverflow.com/a/28583969/852795\n",
    "            cleaned_line = clean_text(line)\n",
    "            encoded_line = cleaned_line.encode(\"utf-8\")\n",
    "            clean_data.write(encoded_line + b\"\\n\")\n",
    "            new_percentage = 100 * processed // number_lines\n",
    "            if (new_percentage > percentage):\n",
    "                print(\"{0:2d}\".format(new_percentage), \"%: \", line, end=\"\")\n",
    "                percentage = new_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the charaters\n",
    "\n",
    "Get counts of all of the characters and select the top ones for processing and filter only sentences with the right charcters. Eliminate any sentences that are too small or too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data file:\n",
      "Done. Writing to file:\n",
      "The top %s chars are: 100\n",
      "\n",
      " !\"#$%&'()*,-./0123456789:;=?@ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz£àáâçèéêíîïôùûü€\n",
      "\n",
      "Reading and filtering data:\n",
      " 1,000,000 :  Our Tip: 7th\n",
      " 2,000,000 :  Premier League: West Ham v Cardiff match preview\n",
      " 3,000,000 :  NCAA Penalizes Montana Football Over Booster Perks\n",
      " 4,000,000 :  Now it's living standards, stupid.\n",
      "Done. Filtered file contains 4,799,651 lines.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "NUMBER_OF_CHARS = 100 # quantity of most popular characters to keep\n",
    "CHAR_FREQUENCY_FILE_NAME = os.path.join(os.path.expanduser(\"data\"), \"news.2013.en.char_frequency.json\")\n",
    "NEWS_FILE_NAME_FILTERED = os.path.join(os.path.expanduser(\"data\"), \"news.2013.en.filtered\")\n",
    "MIN_INPUT_LEN = 5 # minimum number of characters in a sentence\n",
    "MAX_INPUT_LEN = 60 # maximum number of characters in a sentence\n",
    "\n",
    "# create character frequency file\n",
    "if (os.path.isfile(CHAR_FREQUENCY_FILE_NAME)):\n",
    "    print(\"Character frequency file already created.\")\n",
    "else:\n",
    "    counter = Counter()\n",
    "    print(\"Reading data file:\")\n",
    "    for line in open(NEWS_FILE_NAME_CLEAN, encoding=\"utf8\"):\n",
    "        counter.update(line)\n",
    "    print(\"Done. Writing to file:\")\n",
    "    with open(CHAR_FREQUENCY_FILE_NAME, 'wb') as output_file:\n",
    "        output_file.write(json.dumps(counter).encode(\"utf-8\"))\n",
    "    most_popular_chars = {key for key, _value in counter.most_common(NUMBER_OF_CHARS)}\n",
    "    \n",
    "# read top characters that were saved to file\n",
    "chars = json.loads(open(CHAR_FREQUENCY_FILE_NAME).read())\n",
    "counter = Counter(chars)\n",
    "most_popular_chars = {key for key, _value in counter.most_common(NUMBER_OF_CHARS)}\n",
    "print(\"The top %s chars are:\", NUMBER_OF_CHARS)\n",
    "print(\"\".join(sorted(most_popular_chars)))\n",
    "\n",
    "# filter only sentences with the right chars\n",
    "if (os.path.isfile(NEWS_FILE_NAME_FILTERED)):\n",
    "    print(\"\\nFiltered file already created.\")\n",
    "else:\n",
    "    print(\"\\nReading and filtering data:\")\n",
    "    num_lines = 0\n",
    "    with open(NEWS_FILE_NAME_FILTERED, \"wb\") as output_file:\n",
    "        for line in open(NEWS_FILE_NAME_CLEAN, encoding=\"utf8\"):\n",
    "            if line and (not bool(set(line) - most_popular_chars)) and (MAX_INPUT_LEN >= len(line) > MIN_INPUT_LEN):\n",
    "                output_file.write(line.encode(\"utf8\"))\n",
    "                num_lines += 1\n",
    "                if (num_lines % 1000000 == 0):\n",
    "                    print(\"{0:10,d}\".format(num_lines), \": \", line, end=\"\")\n",
    "    print(\"Done. Filtered file contains {:,} lines.\".format(num_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle Done\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import shuffle as random_shuffle\n",
    "\n",
    "NEWS_FILE_NAME_TRAIN = os.path.join(os.path.expanduser(\"data\"), \"news.2013.en.train\")\n",
    "NEWS_FILE_NAME_VALIDATE = os.path.join(os.path.expanduser(\"data\"), \"news.2013.en.validate\")\n",
    "\n",
    "if (os.path.isfile(NEWS_FILE_NAME_TRAIN)):\n",
    "    print(\"Training and Validation files already created.\")\n",
    "else:\n",
    "    answers = open(NEWS_FILE_NAME_FILTERED, encoding=\"utf8\").read().split(\"\\n\")\n",
    "    print('shuffle', end=\" \")\n",
    "    random_shuffle(answers)\n",
    "    print(\"Done\")\n",
    "    # Explicitly set apart 10% for validation data that we never train over\n",
    "    # TODO skip if files already exist\n",
    "    split_at = len(answers) - len(answers) // 10\n",
    "    with open(NEWS_FILE_NAME_TRAIN, \"wb\") as output_file:\n",
    "        output_file.write(\"\\n\".join(answers[:split_at]).encode('utf-8'))\n",
    "    with open(NEWS_FILE_NAME_VALIDATE, \"wb\") as output_file:\n",
    "        output_file.write(\"\\n\".join(answers[split_at:]).encode('utf-8'))\n",
    "    print(\"\\nTraining and Validation files written.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the target data and generate source data by injecting mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 sentence:\n",
      "\n",
      "Source --> The leaidng ladies hat impacted on Sir David's life\n",
      "Target --> The leading ladies that impacted on Sir David's life\n",
      "\n",
      "Source --> They resigned from the Party.\n",
      "Target --> They resigned from the Party.\n",
      "\n",
      "Source --> Everything he went for today went for six or four.\n",
      "Target --> Everything he went for today went for six or four.\n",
      "\n",
      "Source --> Hannon St., 1600 block, 4:33 p.m.\n",
      "Target --> Hannon St., 1600 block, 4:33 p.m.\n",
      "\n",
      "Source --> Because they're holy places.\n",
      "Target --> Because they're holy places.\n",
      "\n",
      "Source --> The next person would have the lighter,\" he says.\n",
      "Target --> The next person would have the lighter,\" he says.\n",
      "\n",
      "Source --> The acquittal of Rabei Osman is also upheld.\n",
      "Target --> The acquittal of Rabei Osman is also upheld.\n",
      "\n",
      "Source --> \"But I'll tell you what,\" he added.\n",
      "Target --> \"But I'll tell you what,\" he added.\n",
      "\n",
      "Source --> It can't make a profit from Kwhat it's got already.\n",
      "Target --> It can't make a profit from what it's got already.\n",
      "\n",
      "Source --> The results were largeyl the same.\n",
      "Target --> The results were largely the same.\n"
     ]
    }
   ],
   "source": [
    "AMOUNT_OF_NOISE = 0.2 / MAX_INPUT_LEN\n",
    "\n",
    "from numpy.random import choice as random_choice, randint as random_randint, seed as random_seed, rand\n",
    "\n",
    "def add_noise_to_string(a_string, amount_of_noise): # Add some artificial spelling mistakes to the string\n",
    "    \n",
    "    CHARS = list(\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .\")\n",
    "\n",
    "    if rand() < amount_of_noise * len(a_string):\n",
    "        # Replace a character with a random character\n",
    "        random_char_position = random_randint(len(a_string))\n",
    "        a_string = a_string[:random_char_position] + random_choice(CHARS[:-1]) + a_string[random_char_position + 1:]\n",
    "    if rand() < amount_of_noise * len(a_string):\n",
    "        # Delete a character\n",
    "        random_char_position = random_randint(len(a_string))\n",
    "        a_string = a_string[:random_char_position] + a_string[random_char_position + 1:]\n",
    "    if len(a_string) < MAX_INPUT_LEN and rand() < amount_of_noise * len(a_string):\n",
    "        # Add a random character\n",
    "        random_char_position = random_randint(len(a_string))\n",
    "        a_string = a_string[:random_char_position] + random_choice(CHARS[:-1]) + a_string[random_char_position:]\n",
    "    if rand() < amount_of_noise * len(a_string):\n",
    "        # Transpose 2 characters\n",
    "        random_char_position = random_randint(len(a_string) - 1)\n",
    "        a_string = (a_string[:random_char_position] + a_string[random_char_position + 1] + \n",
    "                    a_string[random_char_position] + a_string[random_char_position + 2:])\n",
    "    return a_string\n",
    "\n",
    "target_sentences = open(NEWS_FILE_NAME_TRAIN, encoding=\"utf8\").read().split(\"\\n\")    \n",
    "source_sentences = open(NEWS_FILE_NAME_TRAIN, encoding=\"utf8\").read().split(\"\\n\")\n",
    "for i in range(len(source_sentences)):\n",
    "    source_sentences[i] = add_noise_to_string(source_sentences[i], AMOUNT_OF_NOISE)\n",
    "\n",
    "print('\\nFirst 10 sentence:')\n",
    "for i in range (0, 10):\n",
    "    print(\"\\nSource --> \" + source_sentences[i])\n",
    "    print(\"Target --> \" + target_sentences[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Take a look at the initial source and target datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The source is comprised of 4,319,687 sentences. Here are the first 10.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"The leaidng ladies hat impacted on Sir David's life\",\n",
       " 'They resigned from the Party.',\n",
       " 'Everything he went for today went for six or four.',\n",
       " 'Hannon St., 1600 block, 4:33 p.m.',\n",
       " \"Because they're holy places.\",\n",
       " 'The next person would have the lighter,\" he says.',\n",
       " 'The acquittal of Rabei Osman is also upheld.',\n",
       " '\"But I\\'ll tell you what,\" he added.',\n",
       " \"It can't make a profit from Kwhat it's got already.\",\n",
       " 'The results were largeyl the same.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The source is comprised of {:,} sentences. Here are the first 10.\".format(len(source_sentences)))\n",
    "source_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target is comprised of 4,319,687 sentences. Here are the first 10.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"The leading ladies that impacted on Sir David's life\",\n",
       " 'They resigned from the Party.',\n",
       " 'Everything he went for today went for six or four.',\n",
       " 'Hannon St., 1600 block, 4:33 p.m.',\n",
       " \"Because they're holy places.\",\n",
       " 'The next person would have the lighter,\" he says.',\n",
       " 'The acquittal of Rabei Osman is also upheld.',\n",
       " '\"But I\\'ll tell you what,\" he added.',\n",
       " \"It can't make a profit from what it's got already.\",\n",
       " 'The results were largely the same.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The target is comprised of {:,} sentences. Here are the first 10.\".format(len(target_sentences)))\n",
    "target_sentences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Only run this cell to get the tiny data set</font>\n",
    "**Start here if you are going to run with the small dataset** If you are using the big dataset, make sure to skip this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: ['bsaqq', 'npy', 'lbwuj', 'bqv', 'kial', 'tddam', 'edxpjpg', 'nspv', 'huloz', 'kmclq']\n",
      "Target: ['abqqs', 'npy', 'bjluw', 'bqv', 'aikl', 'addmt', 'degjppx', 'npsv', 'hlouz', 'cklmq']\n",
      "\n",
      "The source is comprised of 10,000 sentences.\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to grab the small data sets that came with this model. Otherwise skip it.\n",
    "# The dataset lives in the /data/ folder. At the moment, it is made up of the following files:\n",
    "# letters_source.txt: The list of input letter sequences. Each sequence is its own line. \n",
    "# letters_target.txt: The list of target sequences we'll use in the training process.\n",
    "# Each sequence here is a response to the input sequence in letters_source.txt with the same line number.\n",
    "\n",
    "import helper\n",
    "\n",
    "source_path = 'data/letters_source.txt'\n",
    "target_path = 'data/letters_target.txt'\n",
    "\n",
    "source_sentences = helper.load_data(source_path).split('\\n') # added .split('\\n) to be consistent with big data\n",
    "target_sentences = helper.load_data(target_path).split('\\n')\n",
    "\n",
    "# source_sentences contains the entire input sequence file as text delimited by newline symbols.\n",
    "print(\"Source: {}\".format(source_sentences[:10]))\n",
    "# target_sentences contains the entire output sequence file as text delimited by newline symbols.\n",
    "# Each line corresponds to the line from source_sentences. target_sentences contains a sorted characters of the line.\n",
    "print(\"Target: {}\".format(target_sentences[:10]))\n",
    "\n",
    "print(\"\\nThe source is comprised of {:,} sentences.\".format(len(source_sentences)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess\n",
    "To do anything useful with it, turn the each string into a list of characters. Then convert the characters to their int values as declared in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source INT to letter: {0: '<PAD>', 1: '<UNK>', 2: '<GO>', 3: '<EOS>', 4: 'g', 5: 'x', 6: 'z', 7: 'm', 8: 'u', 9: 'c', 10: 'a', 11: 's', 12: 'r', 13: 'i', 14: 'l', 15: 'f', 16: 'p', 17: 'o', 18: 'n', 19: 'h', 20: 'y', 21: 'v', 22: 'w', 23: 'k', 24: 'd', 25: 't', 26: 'e', 27: 'b', 28: 'j', 29: 'q'}\n",
      "Target INT to letter: {0: '<PAD>', 1: '<UNK>', 2: '<GO>', 3: '<EOS>', 4: 'g', 5: 'x', 6: 'z', 7: 'm', 8: 'u', 9: 'c', 10: 'a', 11: 's', 12: 'r', 13: 'i', 14: 'l', 15: 'f', 16: 'p', 17: 'o', 18: 'n', 19: 'h', 20: 'y', 21: 'v', 22: 'w', 23: 'k', 24: 'd', 25: 't', 26: 'e', 27: 'b', 28: 'j', 29: 'q'}\n",
      "\n",
      "Wrote source_int_to_letter data to file.\n",
      "Wrote target_int_to_letter data to file.\n",
      "Wrote source_letter_to_int data to file.\n",
      "\n",
      "Example source sequence\n",
      "[[27, 11, 10, 29, 29], [18, 16, 20], [14, 27, 22, 8, 28]]\n",
      "\n",
      "Example target sequence\n",
      "[[10, 27, 29, 29, 11, 3], [18, 16, 20, 3], [27, 28, 14, 8, 22, 3]]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def extract_character_vocab(data):\n",
    "    special_words = ['<PAD>', '<UNK>', '<GO>',  '<EOS>']\n",
    "\n",
    "    #set_words = set([character for line in data.split('\\n') for character in line])\n",
    "    set_words = set([character for line in data for character in line])\n",
    "    int_to_vocab = {word_i: word for word_i, word in enumerate(special_words + list(set_words))}\n",
    "    vocab_to_int = {word: word_i for word_i, word in int_to_vocab.items()}\n",
    "\n",
    "    return int_to_vocab, vocab_to_int\n",
    "\n",
    "# Build int2letter and letter2int dicts\n",
    "source_int_to_letter, source_letter_to_int = extract_character_vocab(source_sentences)\n",
    "target_int_to_letter, target_letter_to_int = extract_character_vocab(target_sentences)\n",
    "print(\"Source INT to letter: {}\".format(source_int_to_letter))\n",
    "print(\"Target INT to letter: {}\\n\".format(target_int_to_letter))\n",
    "\n",
    "# Save source_int_to_letter, target_int_to_letter & source_letter_to_int for loading later after graph is saved\n",
    "with open(SOURCE_INT_TO_LETTER, 'w') as output_file:\n",
    "    json.dump(source_int_to_letter, output_file)\n",
    "print(\"Wrote source_int_to_letter data to file.\")\n",
    "with open(TARGET_INT_TO_LETTER, 'w') as output_file:\n",
    "    json.dump(target_int_to_letter, output_file)\n",
    "print(\"Wrote target_int_to_letter data to file.\")\n",
    "with open(SOURCE_LETTER_TO_INT, 'w') as output_file:\n",
    "    json.dump(source_letter_to_int, output_file)\n",
    "print(\"Wrote source_letter_to_int data to file.\\n\")\n",
    "\n",
    "# Convert characters to ids\n",
    "#source_letter_ids = [[source_letter_to_int.get(letter, source_letter_to_int['<UNK>']) for letter in line] for line in source_sentences.split('\\n')]\n",
    "#target_letter_ids = [[target_letter_to_int.get(letter, target_letter_to_int['<UNK>']) for letter in line] + [target_letter_to_int['<EOS>']] for line in target_sentences.split('\\n')] \n",
    "source_letter_ids = [[source_letter_to_int.get(letter, source_letter_to_int['<UNK>']) for letter in line] for line in source_sentences]\n",
    "target_letter_ids = [[target_letter_to_int.get(letter, target_letter_to_int['<UNK>']) for letter in line] + [target_letter_to_int['<EOS>']] for line in target_sentences]\n",
    "\n",
    "print(\"Example source sequence\")\n",
    "print(source_letter_ids[:3])\n",
    "print(\"\\nExample target sequence\")\n",
    "print(target_letter_ids[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 sentence:\n",
      "\n",
      "Source --> [27, 11, 10, 29, 29]\n",
      "Target --> [10, 27, 29, 29, 11, 3]\n",
      "\n",
      "Source --> [18, 16, 20]\n",
      "Target --> [18, 16, 20, 3]\n",
      "\n",
      "Source --> [14, 27, 22, 8, 28]\n",
      "Target --> [27, 28, 14, 8, 22, 3]\n",
      "\n",
      "Source --> [27, 29, 21]\n",
      "Target --> [27, 29, 21, 3]\n",
      "\n",
      "Source --> [23, 13, 10, 14]\n",
      "Target --> [10, 13, 23, 14, 3]\n",
      "\n",
      "Source --> [25, 24, 24, 10, 7]\n",
      "Target --> [10, 24, 24, 7, 25, 3]\n",
      "\n",
      "Source --> [26, 24, 5, 16, 28, 16, 4]\n",
      "Target --> [24, 26, 4, 28, 16, 16, 5, 3]\n",
      "\n",
      "Source --> [18, 11, 16, 21]\n",
      "Target --> [18, 16, 11, 21, 3]\n",
      "\n",
      "Source --> [19, 8, 14, 17, 6]\n",
      "Target --> [19, 14, 17, 8, 6, 3]\n",
      "\n",
      "Source --> [23, 7, 9, 14, 29]\n",
      "Target --> [9, 23, 14, 7, 29, 3]\n"
     ]
    }
   ],
   "source": [
    "print('\\nFirst 10 sentence:')\n",
    "for i in range (0, 10):\n",
    "    print(\"\\nSource --> {}\".format(source_letter_ids[i]))\n",
    "    print(\"Target --> {}\".format(target_letter_ids[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character Sequence to Sequence Model\n",
    "This model was updated to work with TensorFlow 1.1 and builds on the work of Dave Currie. Check out Dave's post [Text Summarization with Amazon Reviews](https://medium.com/towards-data-science/text-summarization-with-amazon-reviews-41801c2210b).\n",
    "<img src=\"images/sequence-to-sequence.jpg\"/>\n",
    "#### Check the Version of TensorFlow and wether or not there's a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.3.0\n",
      "Default GPU Device: /gpu:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    print('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using hyperparameters for the small data with 10,000 source sentences.\n"
     ]
    }
   ],
   "source": [
    "if (len(source_sentences) > 10000):\n",
    "    \n",
    "    # We are using the big data\n",
    "    print(\"Using hyperparameters for the big data with {:,} source sentences.\".format(len(source_sentences)))\n",
    "    epochs = 1       # Number of Epochs\n",
    "    batch_size = 128 # Batch Size\n",
    "\n",
    "    rnn_size = 512   # RNN Size\n",
    "    num_layers = 2   # Number of Layers\n",
    "    encoding_embedding_size = 256 # Encoding embedding Size\n",
    "    decoding_embedding_size = 256 # Decoding embedding Size\n",
    "\n",
    "    learning_rate = 0.001 # Learning Rate\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # We are using the small data\n",
    "    print(\"Using hyperparameters for the small data with {:,} source sentences.\".format(len(source_sentences)))\n",
    "    epochs = 60 # Number of Epochs\n",
    "    batch_size = 128 # Batch Size\n",
    "    rnn_size = 50 # RNN Size    \n",
    "    num_layers = 2 # Number of Layers    \n",
    "    encoding_embedding_size = 15 # Embedding Size\n",
    "    decoding_embedding_size = 15 # Embedding Size    \n",
    "    learning_rate = 0.001 # Learning Rate\n",
    "    \n",
    "# Write batch_size to file for loading after graph has been saved\n",
    "with open(GRAPH_PARAMETERS, 'w') as file:\n",
    "  file.write('%d' % batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_inputs():\n",
    "    input_data = tf.placeholder(tf.int32, [None, None], name='input')\n",
    "    targets = tf.placeholder(tf.int32, [None, None], name='targets')\n",
    "    lr = tf.placeholder(tf.float32, name='learning_rate')\n",
    "\n",
    "    target_sequence_length = tf.placeholder(tf.int32, (None,), name='target_sequence_length')\n",
    "    max_target_sequence_length = tf.reduce_max(target_sequence_length, name='max_target_len')\n",
    "    source_sequence_length = tf.placeholder(tf.int32, (None,), name='source_sequence_length')\n",
    "    \n",
    "    return input_data, targets, lr, target_sequence_length, max_target_sequence_length, source_sequence_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence to Sequence Model\n",
    "\n",
    "We can now start defining the functions that will build the seq2seq model. We are building it from the bottom up with the following components:\n",
    "\n",
    "    2.1 Encoder\n",
    "        - Embedding\n",
    "        - Encoder cell\n",
    "    2.2 Decoder\n",
    "        1- Process decoder inputs\n",
    "        2- Set up the decoder\n",
    "            - Embedding\n",
    "            - Decoder cell\n",
    "            - Dense output layer\n",
    "            - Training decoder\n",
    "            - Inference decoder\n",
    "    2.3 Seq2seq model connecting the encoder and decoder\n",
    "    2.4 Build the training graph hooking up the model with the \n",
    "        optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Encoder\n",
    "\n",
    "The first bit of the model we'll build is the encoder. Here, we'll embed the input data, construct our encoder, then pass the embedded data to the encoder.\n",
    "\n",
    "- Embed the input data using [`tf.contrib.layers.embed_sequence`](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/embed_sequence)\n",
    "<img src=\"images/embed_sequence.png\" />\n",
    "\n",
    "- Pass the embedded input into a stack of RNNs.  Save the RNN state and ignore the output.\n",
    "<img src=\"images/encoder.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def encoding_layer(input_data, rnn_size, num_layers,\n",
    "                   source_sequence_length, source_vocab_size, \n",
    "                   encoding_embedding_size):\n",
    "\n",
    "\n",
    "    # Encoder embedding\n",
    "    enc_embed_input = tf.contrib.layers.embed_sequence(input_data, source_vocab_size, encoding_embedding_size)\n",
    "\n",
    "    # RNN cell\n",
    "    def make_cell(rnn_size):\n",
    "        enc_cell = tf.contrib.rnn.LSTMCell(rnn_size,\n",
    "                                           initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "        return enc_cell\n",
    "\n",
    "    enc_cell = tf.contrib.rnn.MultiRNNCell([make_cell(rnn_size) for _ in range(num_layers)])\n",
    "    \n",
    "    enc_output, enc_state = tf.nn.dynamic_rnn(enc_cell, enc_embed_input, sequence_length=source_sequence_length, dtype=tf.float32)\n",
    "    \n",
    "    return enc_output, enc_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Decoder\n",
    "\n",
    "The decoder is probably the most involved part of this model. The following steps are needed to create it:\n",
    "\n",
    "    1- Process decoder inputs\n",
    "    2- Set up the decoder components\n",
    "        - Embedding\n",
    "        - Decoder cell\n",
    "        - Dense output layer\n",
    "        - Training decoder\n",
    "        - Inference decoder\n",
    "\n",
    "\n",
    "### Process Decoder Input\n",
    "\n",
    "\n",
    "In the training process, the target sequences will be used in two different places:\n",
    "\n",
    " 1. Using them to calculate the loss\n",
    " 2. Feeding them to the decoder during training to make the model more robust.\n",
    "\n",
    "Now we need to address the second point. Let's assume our targets look like this in their letter/word form (we're doing this for readibility. At this point in the code, these sequences would be in int form):\n",
    "\n",
    "\n",
    "<img src=\"images/targets_1.png\"/>\n",
    "\n",
    "We need to do a simple transformation on the tensor before feeding it to the decoder:\n",
    "\n",
    "1- We will feed an item of the sequence to the decoder at each time step. Think about the last timestep -- where the decoder outputs the final word in its output. The input to that step is the item before last from the target sequence. The decoder has no use for the last item in the target sequence in this scenario. So we'll need to remove the last item. \n",
    "\n",
    "We do that using tensorflow's tf.strided_slice() method. We hand it the tensor, and the index of where to start and where to end the cutting.\n",
    "\n",
    "<img src=\"images/strided_slice_1.png\"/>\n",
    "\n",
    "2- The first item in each sequence we feed to the decoder has to be GO symbol. So We'll add that to the beginning.\n",
    "\n",
    "\n",
    "<img src=\"images/targets_add_go.png\"/>\n",
    "\n",
    "\n",
    "Now the tensor is ready to be fed to the decoder. It looks like this (if we convert from ints to letters/symbols):\n",
    "\n",
    "<img src=\"images/targets_after_processing_1.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process the input we'll feed to the decoder\n",
    "def process_decoder_input(target_data, vocab_to_int, batch_size):\n",
    "    '''Remove the last word id from each batch and concat the <GO> to the begining of each batch'''\n",
    "    ending = tf.strided_slice(target_data, [0, 0], [batch_size, -1], [1, 1])\n",
    "    dec_input = tf.concat([tf.fill([batch_size, 1], vocab_to_int['<GO>']), ending], 1)\n",
    "\n",
    "    return dec_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Set up the decoder components\n",
    "\n",
    "        - Embedding\n",
    "        - Decoder cell\n",
    "        - Dense output layer\n",
    "        - Training decoder\n",
    "        - Inference decoder\n",
    "\n",
    "#### 1- Embedding\n",
    "Now that we have prepared the inputs to the training decoder, we need to embed them so they can be ready to be passed to the decoder. \n",
    "\n",
    "We'll create an embedding matrix like the following then have tf.nn.embedding_lookup convert our input to its embedded equivalent:\n",
    "<img src=\"images/embeddings.png\" />\n",
    "\n",
    "#### 2- Decoder Cell\n",
    "Then we declare our decoder cell. Just like the encoder, we'll use an tf.contrib.rnn.LSTMCell here as well.\n",
    "\n",
    "We need to declare a decoder for the training process, and a decoder for the inference/prediction process. These two decoders will share their parameters (so that all the weights and biases that are set during the training phase can be used when we deploy the model).\n",
    "\n",
    "First, we'll need to define the type of cell we'll be using for our decoder RNNs. We opted for LSTM.\n",
    "\n",
    "#### 3- Dense output layer\n",
    "Before we move to declaring our decoders, we'll need to create the output layer, which will be a tensorflow.python.layers.core.Dense layer that translates the outputs of the decoder to logits that tell us which element of the decoder vocabulary the decoder is choosing to output at each time step.\n",
    "\n",
    "#### 4- Training decoder\n",
    "Essentially, we'll be creating two decoders which share their parameters. One for training and one for inference. The two are similar in that both created using tf.contrib.seq2seq.**BasicDecoder** and tf.contrib.seq2seq.**dynamic_decode**. They differ, however, in that we feed the the target sequences as inputs to the training decoder at each time step to make it more robust.\n",
    "\n",
    "We can think of the training decoder as looking like this (except that it works with sequences in batches):\n",
    "<img src=\"images/sequence-to-sequence-training-decoder.png\"/>\n",
    "\n",
    "The training decoder **does not** feed the output of each time step to the next. Rather, the inputs to the decoder time steps are the target sequence from the training dataset (the orange letters).\n",
    "\n",
    "#### 5- Inference decoder\n",
    "The inference decoder is the one we'll use when we deploy our model to the wild.\n",
    "\n",
    "<img src=\"images/sequence-to-sequence-inference-decoder.png\"/>\n",
    "\n",
    "We'll hand our encoder hidden state to both the training and inference decoders and have it process its output. TensorFlow handles most of the logic for us. We just have to use the appropriate methods from tf.contrib.seq2seq and supply them with the appropriate inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decoding_layer(target_letter_to_int, decoding_embedding_size, num_layers, rnn_size,\n",
    "                   target_sequence_length, max_target_sequence_length, enc_state, dec_input):\n",
    "    # 1. Decoder Embedding\n",
    "    target_vocab_size = len(target_letter_to_int)\n",
    "    dec_embeddings = tf.Variable(tf.random_uniform([target_vocab_size, decoding_embedding_size]))\n",
    "    dec_embed_input = tf.nn.embedding_lookup(dec_embeddings, dec_input)\n",
    "\n",
    "    # 2. Construct the decoder cell\n",
    "    def make_cell(rnn_size):\n",
    "        dec_cell = tf.contrib.rnn.LSTMCell(rnn_size,\n",
    "                                           initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "        return dec_cell\n",
    "\n",
    "    dec_cell = tf.contrib.rnn.MultiRNNCell([make_cell(rnn_size) for _ in range(num_layers)])\n",
    "     \n",
    "    # 3. Dense layer to translate the decoder's output at each time \n",
    "    # step into a choice from the target vocabulary\n",
    "    output_layer = Dense(target_vocab_size,\n",
    "                         kernel_initializer = tf.truncated_normal_initializer(mean = 0.0, stddev=0.1))\n",
    "\n",
    "\n",
    "    # 4. Set up a training decoder and an inference decoder\n",
    "    # Training Decoder\n",
    "    with tf.variable_scope(\"decode\"):\n",
    "\n",
    "        # Helper for the training process. Used by BasicDecoder to read inputs.\n",
    "        training_helper = tf.contrib.seq2seq.TrainingHelper(inputs=dec_embed_input,\n",
    "                                                            sequence_length=target_sequence_length,\n",
    "                                                            time_major=False)\n",
    "        \n",
    "        \n",
    "        # Basic decoder\n",
    "        training_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n",
    "                                                           training_helper,\n",
    "                                                           enc_state,\n",
    "                                                           output_layer) \n",
    "        \n",
    "        # Perform dynamic decoding using the decoder\n",
    "        training_decoder_output = tf.contrib.seq2seq.dynamic_decode(training_decoder,\n",
    "                                                                       impute_finished=True,\n",
    "                                                                       maximum_iterations=max_target_sequence_length)[0]\n",
    "    # 5. Inference Decoder\n",
    "    # Reuses the same parameters trained by the training process\n",
    "    with tf.variable_scope(\"decode\", reuse=True):\n",
    "        start_tokens = tf.tile(tf.constant([target_letter_to_int['<GO>']], dtype=tf.int32), [batch_size], name='start_tokens')\n",
    "\n",
    "        # Helper for the inference process.\n",
    "        inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(dec_embeddings,\n",
    "                                                                start_tokens,\n",
    "                                                                target_letter_to_int['<EOS>'])\n",
    "\n",
    "        # Basic decoder\n",
    "        inference_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n",
    "                                                        inference_helper,\n",
    "                                                        enc_state,\n",
    "                                                        output_layer)\n",
    "        \n",
    "        # Perform dynamic decoding using the decoder\n",
    "        inference_decoder_output = tf.contrib.seq2seq.dynamic_decode(inference_decoder,\n",
    "                                                            impute_finished=True,\n",
    "                                                            maximum_iterations=max_target_sequence_length)[0]\n",
    "         \n",
    "\n",
    "    \n",
    "    return training_decoder_output, inference_decoder_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Seq2seq model \n",
    "Let's now go a step above, and hook up the encoder and decoder using the methods we just declared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq2seq_model(input_data, targets, lr, target_sequence_length, \n",
    "                  max_target_sequence_length, source_sequence_length,\n",
    "                  source_vocab_size, target_vocab_size,\n",
    "                  enc_embedding_size, dec_embedding_size, \n",
    "                  rnn_size, num_layers):\n",
    "    \n",
    "    # Pass the input data through the encoder. We'll ignore the encoder output, but use the state\n",
    "    _, enc_state = encoding_layer(input_data, \n",
    "                                  rnn_size, \n",
    "                                  num_layers, \n",
    "                                  source_sequence_length,\n",
    "                                  source_vocab_size, \n",
    "                                  encoding_embedding_size)\n",
    "    \n",
    "    \n",
    "    # Prepare the target sequences we'll feed to the decoder in training mode\n",
    "    dec_input = process_decoder_input(targets, target_letter_to_int, batch_size)\n",
    "    \n",
    "    # Pass encoder state and decoder inputs to the decoders\n",
    "    training_decoder_output, inference_decoder_output = decoding_layer(target_letter_to_int, \n",
    "                                                                       decoding_embedding_size, \n",
    "                                                                       num_layers, \n",
    "                                                                       rnn_size,\n",
    "                                                                       target_sequence_length,\n",
    "                                                                       max_target_sequence_length,\n",
    "                                                                       enc_state, \n",
    "                                                                       dec_input) \n",
    "    \n",
    "    return training_decoder_output, inference_decoder_output\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model outputs *training_decoder_output* and *inference_decoder_output* both contain a 'rnn_output' logits tensor that looks like this:\n",
    "\n",
    "<img src=\"images/logits.png\"/>\n",
    "\n",
    "The logits we get from the training tensor we'll pass to tf.contrib.seq2seq.**sequence_loss()** to calculate the loss and ultimately the gradient.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.layers.core import Dense\n",
    "\n",
    "# Build the graph\n",
    "train_graph = tf.Graph()\n",
    "# Set the graph to default to ensure that it is ready for training\n",
    "with train_graph.as_default():\n",
    "    \n",
    "    # Load the model inputs    \n",
    "    input_data, targets, lr, target_sequence_length, max_target_sequence_length, source_sequence_length = get_model_inputs()\n",
    "    \n",
    "    # Create the training and inference logits\n",
    "    training_decoder_output, inference_decoder_output = seq2seq_model(input_data, \n",
    "                                                                      targets, \n",
    "                                                                      lr, \n",
    "                                                                      target_sequence_length, \n",
    "                                                                      max_target_sequence_length, \n",
    "                                                                      source_sequence_length,\n",
    "                                                                      len(source_letter_to_int),\n",
    "                                                                      len(target_letter_to_int),\n",
    "                                                                      encoding_embedding_size, \n",
    "                                                                      decoding_embedding_size, \n",
    "                                                                      rnn_size, \n",
    "                                                                      num_layers)    \n",
    "    \n",
    "    # Create tensors for the training logits and inference logits\n",
    "    training_logits = tf.identity(training_decoder_output.rnn_output, 'logits')\n",
    "    inference_logits = tf.identity(inference_decoder_output.sample_id, name='predictions')\n",
    "    \n",
    "    # Create the weights for sequence_loss\n",
    "    masks = tf.sequence_mask(target_sequence_length, max_target_sequence_length, dtype=tf.float32, name='masks')\n",
    "\n",
    "    with tf.name_scope(\"optimization\"):\n",
    "        \n",
    "        # Loss function\n",
    "        cost = tf.contrib.seq2seq.sequence_loss(\n",
    "            training_logits,\n",
    "            targets,\n",
    "            masks)\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "        # Gradient Clipping\n",
    "        gradients = optimizer.compute_gradients(cost)\n",
    "        capped_gradients = [(tf.clip_by_value(grad, -5., 5.), var) for grad, var in gradients if grad is not None]\n",
    "        train_op = optimizer.apply_gradients(capped_gradients)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Batches\n",
    "\n",
    "There's little processing involved when we retreive the batches. This is a simple example assuming batch_size = 2\n",
    "\n",
    "Source sequences (it's actually in int form, we're showing the characters for clarity):\n",
    "\n",
    "<img src=\"images/source_batch.png\" />\n",
    "\n",
    "Target sequences (also in int, but showing letters for clarity):\n",
    "\n",
    "<img src=\"images/target_batch.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_sentence_batch(sentence_batch, pad_int):\n",
    "    \"\"\"Pad sentences with <PAD> so that each sentence of a batch has the same length\"\"\"\n",
    "    max_sentence = max([len(sentence) for sentence in sentence_batch])\n",
    "    return [sentence + [pad_int] * (max_sentence - len(sentence)) for sentence in sentence_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_batches(targets, sources, batch_size, source_pad_int, target_pad_int):\n",
    "    \"\"\"Batch targets, sources, and the lengths of their sentences together\"\"\"\n",
    "    for batch_i in range(0, len(sources)//batch_size):\n",
    "        start_i = batch_i * batch_size\n",
    "        sources_batch = sources[start_i:start_i + batch_size]\n",
    "        targets_batch = targets[start_i:start_i + batch_size]\n",
    "        pad_sources_batch = np.array(pad_sentence_batch(sources_batch, source_pad_int))\n",
    "        pad_targets_batch = np.array(pad_sentence_batch(targets_batch, target_pad_int))\n",
    "        \n",
    "        # Need the lengths for the _lengths parameters\n",
    "        pad_targets_lengths = []\n",
    "        for target in pad_targets_batch:\n",
    "            pad_targets_lengths.append(len(target))\n",
    "        \n",
    "        pad_source_lengths = []\n",
    "        for source in pad_sources_batch:\n",
    "            pad_source_lengths.append(len(source))\n",
    "        \n",
    "        yield pad_targets_batch, pad_sources_batch, pad_targets_lengths, pad_source_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "We're now ready to train our model. If you run into OOM (out of memory) issues during training, try to decrease the batch_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/60 Batch     20/77 Inputs (000)       2 - Loss:  2.589  - Validation loss:  2.562\n",
      "Epoch   1/60 Batch     40/77 Inputs (000)       5 - Loss:  2.288  - Validation loss:  2.240\n",
      "Epoch   1/60 Batch     60/77 Inputs (000)       7 - Loss:  1.996  - Validation loss:  2.034\n",
      "Epoch   2/60 Batch     20/77 Inputs (000)      12 - Loss:  1.668  - Validation loss:  1.749\n",
      "Epoch   2/60 Batch     40/77 Inputs (000)      14 - Loss:  1.684  - Validation loss:  1.638\n",
      "Epoch   2/60 Batch     60/77 Inputs (000)      17 - Loss:  1.505  - Validation loss:  1.538\n",
      "Epoch   3/60 Batch     20/77 Inputs (000)      22 - Loss:  1.365  - Validation loss:  1.436\n",
      "Epoch   3/60 Batch     40/77 Inputs (000)      24 - Loss:  1.448  - Validation loss:  1.410\n",
      "Epoch   3/60 Batch     60/77 Inputs (000)      27 - Loss:  1.347  - Validation loss:  1.377\n",
      "Epoch   4/60 Batch     20/77 Inputs (000)      32 - Loss:  1.229  - Validation loss:  1.299\n",
      "Epoch   4/60 Batch     40/77 Inputs (000)      34 - Loss:  1.284  - Validation loss:  1.251\n",
      "Epoch   4/60 Batch     60/77 Inputs (000)      37 - Loss:  1.167  - Validation loss:  1.209\n",
      "Epoch   5/60 Batch     20/77 Inputs (000)      42 - Loss:  1.112  - Validation loss:  1.162\n",
      "Epoch   5/60 Batch     40/77 Inputs (000)      44 - Loss:  1.186  - Validation loss:  1.151\n",
      "Epoch   5/60 Batch     60/77 Inputs (000)      47 - Loss:  1.092  - Validation loss:  1.131\n",
      "Epoch   6/60 Batch     20/77 Inputs (000)      51 - Loss:  1.062  - Validation loss:  1.105\n",
      "Epoch   6/60 Batch     40/77 Inputs (000)      54 - Loss:  1.134  - Validation loss:  1.097\n",
      "Epoch   6/60 Batch     60/77 Inputs (000)      57 - Loss:  1.040  - Validation loss:  1.076\n",
      "Epoch   7/60 Batch     20/77 Inputs (000)      61 - Loss:  0.989  - Validation loss:  1.028\n",
      "Epoch   7/60 Batch     40/77 Inputs (000)      64 - Loss:  1.046  - Validation loss:  1.005\n",
      "Epoch   7/60 Batch     60/77 Inputs (000)      66 - Loss:  0.963  - Validation loss:  0.973\n",
      "Epoch   8/60 Batch     20/77 Inputs (000)      71 - Loss:  0.878  - Validation loss:  0.920\n",
      "Epoch   8/60 Batch     40/77 Inputs (000)      74 - Loss:  0.918  - Validation loss:  0.896\n",
      "Epoch   8/60 Batch     60/77 Inputs (000)      76 - Loss:  0.887  - Validation loss:  0.873\n",
      "Epoch   9/60 Batch     20/77 Inputs (000)      81 - Loss:  0.793  - Validation loss:  0.843\n",
      "Epoch   9/60 Batch     40/77 Inputs (000)      84 - Loss:  0.828  - Validation loss:  0.818\n",
      "Epoch   9/60 Batch     60/77 Inputs (000)      86 - Loss:  0.748  - Validation loss:  0.793\n",
      "Epoch  10/60 Batch     20/77 Inputs (000)      91 - Loss:  0.717  - Validation loss:  0.759\n",
      "Epoch  10/60 Batch     40/77 Inputs (000)      93 - Loss:  0.756  - Validation loss:  0.745\n",
      "Epoch  10/60 Batch     60/77 Inputs (000)      96 - Loss:  0.681  - Validation loss:  0.725\n",
      "Epoch  11/60 Batch     20/77 Inputs (000)     101 - Loss:  0.657  - Validation loss:  0.694\n",
      "Epoch  11/60 Batch     40/77 Inputs (000)     103 - Loss:  0.692  - Validation loss:  0.680\n",
      "Epoch  11/60 Batch     60/77 Inputs (000)     106 - Loss:  0.615  - Validation loss:  0.661\n",
      "Epoch  12/60 Batch     20/77 Inputs (000)     111 - Loss:  0.596  - Validation loss:  0.634\n",
      "Epoch  12/60 Batch     40/77 Inputs (000)     113 - Loss:  0.628  - Validation loss:  0.623\n",
      "Epoch  12/60 Batch     60/77 Inputs (000)     116 - Loss:  0.560  - Validation loss:  0.608\n",
      "Epoch  13/60 Batch     20/77 Inputs (000)     121 - Loss:  0.546  - Validation loss:  0.584\n",
      "Epoch  13/60 Batch     40/77 Inputs (000)     123 - Loss:  0.578  - Validation loss:  0.575\n",
      "Epoch  13/60 Batch     60/77 Inputs (000)     126 - Loss:  0.516  - Validation loss:  0.560\n",
      "Epoch  14/60 Batch     20/77 Inputs (000)     130 - Loss:  0.496  - Validation loss:  0.534\n",
      "Epoch  14/60 Batch     40/77 Inputs (000)     133 - Loss:  0.530  - Validation loss:  0.524\n",
      "Epoch  14/60 Batch     60/77 Inputs (000)     136 - Loss:  0.471  - Validation loss:  0.506\n",
      "Epoch  15/60 Batch     20/77 Inputs (000)     140 - Loss:  0.437  - Validation loss:  0.481\n",
      "Epoch  15/60 Batch     40/77 Inputs (000)     143 - Loss:  0.477  - Validation loss:  0.467\n",
      "Epoch  15/60 Batch     60/77 Inputs (000)     145 - Loss:  0.421  - Validation loss:  0.450\n",
      "Epoch  16/60 Batch     20/77 Inputs (000)     150 - Loss:  0.382  - Validation loss:  0.430\n",
      "Epoch  16/60 Batch     40/77 Inputs (000)     153 - Loss:  0.427  - Validation loss:  0.418\n",
      "Epoch  16/60 Batch     60/77 Inputs (000)     155 - Loss:  0.376  - Validation loss:  0.403\n",
      "Epoch  17/60 Batch     20/77 Inputs (000)     160 - Loss:  0.336  - Validation loss:  0.382\n",
      "Epoch  17/60 Batch     40/77 Inputs (000)     163 - Loss:  0.380  - Validation loss:  0.370\n",
      "Epoch  17/60 Batch     60/77 Inputs (000)     165 - Loss:  0.336  - Validation loss:  0.359\n",
      "Epoch  18/60 Batch     20/77 Inputs (000)     170 - Loss:  0.295  - Validation loss:  0.342\n",
      "Epoch  18/60 Batch     40/77 Inputs (000)     172 - Loss:  0.338  - Validation loss:  0.330\n",
      "Epoch  18/60 Batch     60/77 Inputs (000)     175 - Loss:  0.301  - Validation loss:  0.327\n",
      "Epoch  19/60 Batch     20/77 Inputs (000)     180 - Loss:  0.259  - Validation loss:  0.307\n",
      "Epoch  19/60 Batch     40/77 Inputs (000)     182 - Loss:  0.299  - Validation loss:  0.295\n",
      "Epoch  19/60 Batch     60/77 Inputs (000)     185 - Loss:  0.269  - Validation loss:  0.295\n",
      "Epoch  20/60 Batch     20/77 Inputs (000)     190 - Loss:  0.227  - Validation loss:  0.274\n",
      "Epoch  20/60 Batch     40/77 Inputs (000)     192 - Loss:  0.265  - Validation loss:  0.264\n",
      "Epoch  20/60 Batch     60/77 Inputs (000)     195 - Loss:  0.241  - Validation loss:  0.273\n",
      "Epoch  21/60 Batch     20/77 Inputs (000)     200 - Loss:  0.199  - Validation loss:  0.249\n",
      "Epoch  21/60 Batch     40/77 Inputs (000)     202 - Loss:  0.235  - Validation loss:  0.240\n",
      "Epoch  21/60 Batch     60/77 Inputs (000)     205 - Loss:  0.212  - Validation loss:  0.238\n",
      "Epoch  22/60 Batch     20/77 Inputs (000)     209 - Loss:  0.175  - Validation loss:  0.225\n",
      "Epoch  22/60 Batch     40/77 Inputs (000)     212 - Loss:  0.210  - Validation loss:  0.219\n",
      "Epoch  22/60 Batch     60/77 Inputs (000)     214 - Loss:  0.189  - Validation loss:  0.215\n",
      "Epoch  23/60 Batch     20/77 Inputs (000)     219 - Loss:  0.155  - Validation loss:  0.204\n",
      "Epoch  23/60 Batch     40/77 Inputs (000)     222 - Loss:  0.186  - Validation loss:  0.199\n",
      "Epoch  23/60 Batch     60/77 Inputs (000)     224 - Loss:  0.168  - Validation loss:  0.192\n",
      "Epoch  24/60 Batch     20/77 Inputs (000)     229 - Loss:  0.137  - Validation loss:  0.184\n",
      "Epoch  24/60 Batch     40/77 Inputs (000)     232 - Loss:  0.165  - Validation loss:  0.178\n",
      "Epoch  24/60 Batch     60/77 Inputs (000)     234 - Loss:  0.152  - Validation loss:  0.170\n",
      "Epoch  25/60 Batch     20/77 Inputs (000)     239 - Loss:  0.121  - Validation loss:  0.166\n",
      "Epoch  25/60 Batch     40/77 Inputs (000)     242 - Loss:  0.147  - Validation loss:  0.160\n",
      "Epoch  25/60 Batch     60/77 Inputs (000)     244 - Loss:  0.133  - Validation loss:  0.153\n",
      "Epoch  26/60 Batch     20/77 Inputs (000)     249 - Loss:  0.107  - Validation loss:  0.148\n",
      "Epoch  26/60 Batch     40/77 Inputs (000)     251 - Loss:  0.129  - Validation loss:  0.144\n",
      "Epoch  26/60 Batch     60/77 Inputs (000)     254 - Loss:  0.115  - Validation loss:  0.137\n",
      "Epoch  27/60 Batch     20/77 Inputs (000)     259 - Loss:  0.097  - Validation loss:  0.134\n",
      "Epoch  27/60 Batch     40/77 Inputs (000)     261 - Loss:  0.116  - Validation loss:  0.133\n",
      "Epoch  27/60 Batch     60/77 Inputs (000)     264 - Loss:  0.103  - Validation loss:  0.123\n",
      "Epoch  28/60 Batch     20/77 Inputs (000)     269 - Loss:  0.091  - Validation loss:  0.122\n",
      "Epoch  28/60 Batch     40/77 Inputs (000)     271 - Loss:  0.106  - Validation loss:  0.119\n",
      "Epoch  28/60 Batch     60/77 Inputs (000)     274 - Loss:  0.090  - Validation loss:  0.114\n",
      "Epoch  29/60 Batch     20/77 Inputs (000)     278 - Loss:  0.074  - Validation loss:  0.111\n",
      "Epoch  29/60 Batch     40/77 Inputs (000)     281 - Loss:  0.103  - Validation loss:  0.116\n",
      "Epoch  29/60 Batch     60/77 Inputs (000)     284 - Loss:  0.237  - Validation loss:  0.271\n",
      "Epoch  30/60 Batch     20/77 Inputs (000)     288 - Loss:  0.081  - Validation loss:  0.110\n",
      "Epoch  30/60 Batch     40/77 Inputs (000)     291 - Loss:  0.089  - Validation loss:  0.101\n",
      "Epoch  30/60 Batch     60/77 Inputs (000)     293 - Loss:  0.077  - Validation loss:  0.098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  31/60 Batch     20/77 Inputs (000)     298 - Loss:  0.063  - Validation loss:  0.094\n",
      "Epoch  31/60 Batch     40/77 Inputs (000)     301 - Loss:  0.078  - Validation loss:  0.090\n",
      "Epoch  31/60 Batch     60/77 Inputs (000)     303 - Loss:  0.068  - Validation loss:  0.088\n",
      "Epoch  32/60 Batch     20/77 Inputs (000)     308 - Loss:  0.057  - Validation loss:  0.086\n",
      "Epoch  32/60 Batch     40/77 Inputs (000)     311 - Loss:  0.070  - Validation loss:  0.082\n",
      "Epoch  32/60 Batch     60/77 Inputs (000)     313 - Loss:  0.061  - Validation loss:  0.081\n",
      "Epoch  33/60 Batch     20/77 Inputs (000)     318 - Loss:  0.051  - Validation loss:  0.079\n",
      "Epoch  33/60 Batch     40/77 Inputs (000)     321 - Loss:  0.063  - Validation loss:  0.076\n",
      "Epoch  33/60 Batch     60/77 Inputs (000)     323 - Loss:  0.056  - Validation loss:  0.075\n",
      "Epoch  34/60 Batch     20/77 Inputs (000)     328 - Loss:  0.047  - Validation loss:  0.073\n",
      "Epoch  34/60 Batch     40/77 Inputs (000)     330 - Loss:  0.057  - Validation loss:  0.070\n",
      "Epoch  34/60 Batch     60/77 Inputs (000)     333 - Loss:  0.051  - Validation loss:  0.069\n",
      "Epoch  35/60 Batch     20/77 Inputs (000)     338 - Loss:  0.043  - Validation loss:  0.068\n",
      "Epoch  35/60 Batch     40/77 Inputs (000)     340 - Loss:  0.052  - Validation loss:  0.065\n",
      "Epoch  35/60 Batch     60/77 Inputs (000)     343 - Loss:  0.047  - Validation loss:  0.064\n",
      "Epoch  36/60 Batch     20/77 Inputs (000)     348 - Loss:  0.039  - Validation loss:  0.063\n",
      "Epoch  36/60 Batch     40/77 Inputs (000)     350 - Loss:  0.048  - Validation loss:  0.061\n",
      "Epoch  36/60 Batch     60/77 Inputs (000)     353 - Loss:  0.043  - Validation loss:  0.060\n",
      "Epoch  37/60 Batch     20/77 Inputs (000)     357 - Loss:  0.036  - Validation loss:  0.059\n",
      "Epoch  37/60 Batch     40/77 Inputs (000)     360 - Loss:  0.044  - Validation loss:  0.057\n",
      "Epoch  37/60 Batch     60/77 Inputs (000)     363 - Loss:  0.040  - Validation loss:  0.056\n",
      "Epoch  38/60 Batch     20/77 Inputs (000)     367 - Loss:  0.033  - Validation loss:  0.055\n",
      "Epoch  38/60 Batch     40/77 Inputs (000)     370 - Loss:  0.040  - Validation loss:  0.053\n",
      "Epoch  38/60 Batch     60/77 Inputs (000)     372 - Loss:  0.037  - Validation loss:  0.052\n",
      "Epoch  39/60 Batch     20/77 Inputs (000)     377 - Loss:  0.030  - Validation loss:  0.051\n",
      "Epoch  39/60 Batch     40/77 Inputs (000)     380 - Loss:  0.037  - Validation loss:  0.050\n",
      "Epoch  39/60 Batch     60/77 Inputs (000)     382 - Loss:  0.034  - Validation loss:  0.049\n",
      "Epoch  40/60 Batch     20/77 Inputs (000)     387 - Loss:  0.028  - Validation loss:  0.048\n",
      "Epoch  40/60 Batch     40/77 Inputs (000)     390 - Loss:  0.034  - Validation loss:  0.047\n",
      "Epoch  40/60 Batch     60/77 Inputs (000)     392 - Loss:  0.031  - Validation loss:  0.046\n",
      "Epoch  41/60 Batch     20/77 Inputs (000)     397 - Loss:  0.026  - Validation loss:  0.045\n",
      "Epoch  41/60 Batch     40/77 Inputs (000)     400 - Loss:  0.031  - Validation loss:  0.044\n",
      "Epoch  41/60 Batch     60/77 Inputs (000)     402 - Loss:  0.029  - Validation loss:  0.043\n",
      "Epoch  42/60 Batch     20/77 Inputs (000)     407 - Loss:  0.024  - Validation loss:  0.042\n",
      "Epoch  42/60 Batch     40/77 Inputs (000)     409 - Loss:  0.029  - Validation loss:  0.042\n",
      "Epoch  42/60 Batch     60/77 Inputs (000)     412 - Loss:  0.027  - Validation loss:  0.040\n",
      "Epoch  43/60 Batch     20/77 Inputs (000)     417 - Loss:  0.022  - Validation loss:  0.040\n",
      "Epoch  43/60 Batch     40/77 Inputs (000)     419 - Loss:  0.027  - Validation loss:  0.039\n",
      "Epoch  43/60 Batch     60/77 Inputs (000)     422 - Loss:  0.025  - Validation loss:  0.038\n",
      "Epoch  44/60 Batch     20/77 Inputs (000)     427 - Loss:  0.020  - Validation loss:  0.037\n",
      "Epoch  44/60 Batch     40/77 Inputs (000)     429 - Loss:  0.025  - Validation loss:  0.037\n",
      "Epoch  44/60 Batch     60/77 Inputs (000)     432 - Loss:  0.023  - Validation loss:  0.036\n",
      "Epoch  45/60 Batch     20/77 Inputs (000)     436 - Loss:  0.019  - Validation loss:  0.035\n",
      "Epoch  45/60 Batch     40/77 Inputs (000)     439 - Loss:  0.023  - Validation loss:  0.035\n",
      "Epoch  45/60 Batch     60/77 Inputs (000)     442 - Loss:  0.022  - Validation loss:  0.034\n",
      "Epoch  46/60 Batch     20/77 Inputs (000)     446 - Loss:  0.018  - Validation loss:  0.033\n",
      "Epoch  46/60 Batch     40/77 Inputs (000)     449 - Loss:  0.021  - Validation loss:  0.033\n",
      "Epoch  46/60 Batch     60/77 Inputs (000)     451 - Loss:  0.020  - Validation loss:  0.032\n",
      "Epoch  47/60 Batch     20/77 Inputs (000)     456 - Loss:  0.016  - Validation loss:  0.032\n",
      "Epoch  47/60 Batch     40/77 Inputs (000)     459 - Loss:  0.020  - Validation loss:  0.032\n",
      "Epoch  47/60 Batch     60/77 Inputs (000)     461 - Loss:  0.019  - Validation loss:  0.030\n",
      "Epoch  48/60 Batch     20/77 Inputs (000)     466 - Loss:  0.015  - Validation loss:  0.030\n",
      "Epoch  48/60 Batch     40/77 Inputs (000)     469 - Loss:  0.018  - Validation loss:  0.030\n",
      "Epoch  48/60 Batch     60/77 Inputs (000)     471 - Loss:  0.018  - Validation loss:  0.029\n",
      "Epoch  49/60 Batch     20/77 Inputs (000)     476 - Loss:  0.014  - Validation loss:  0.028\n",
      "Epoch  49/60 Batch     40/77 Inputs (000)     478 - Loss:  0.017  - Validation loss:  0.028\n",
      "Epoch  49/60 Batch     60/77 Inputs (000)     481 - Loss:  0.017  - Validation loss:  0.027\n",
      "Epoch  50/60 Batch     20/77 Inputs (000)     486 - Loss:  0.013  - Validation loss:  0.027\n",
      "Epoch  50/60 Batch     40/77 Inputs (000)     488 - Loss:  0.016  - Validation loss:  0.027\n",
      "Epoch  50/60 Batch     60/77 Inputs (000)     491 - Loss:  0.015  - Validation loss:  0.026\n",
      "Epoch  51/60 Batch     20/77 Inputs (000)     496 - Loss:  0.013  - Validation loss:  0.025\n",
      "Epoch  51/60 Batch     40/77 Inputs (000)     498 - Loss:  0.015  - Validation loss:  0.026\n",
      "Epoch  51/60 Batch     60/77 Inputs (000)     501 - Loss:  0.014  - Validation loss:  0.024\n",
      "Epoch  52/60 Batch     20/77 Inputs (000)     506 - Loss:  0.012  - Validation loss:  0.024\n",
      "Epoch  52/60 Batch     40/77 Inputs (000)     508 - Loss:  0.014  - Validation loss:  0.024\n",
      "Epoch  52/60 Batch     60/77 Inputs (000)     511 - Loss:  0.014  - Validation loss:  0.023\n",
      "Epoch  53/60 Batch     20/77 Inputs (000)     515 - Loss:  0.011  - Validation loss:  0.023\n",
      "Epoch  53/60 Batch     40/77 Inputs (000)     518 - Loss:  0.013  - Validation loss:  0.023\n",
      "Epoch  53/60 Batch     60/77 Inputs (000)     521 - Loss:  0.013  - Validation loss:  0.022\n",
      "Epoch  54/60 Batch     20/77 Inputs (000)     525 - Loss:  0.010  - Validation loss:  0.022\n",
      "Epoch  54/60 Batch     40/77 Inputs (000)     528 - Loss:  0.012  - Validation loss:  0.022\n",
      "Epoch  54/60 Batch     60/77 Inputs (000)     530 - Loss:  0.012  - Validation loss:  0.021\n",
      "Epoch  55/60 Batch     20/77 Inputs (000)     535 - Loss:  0.010  - Validation loss:  0.021\n",
      "Epoch  55/60 Batch     40/77 Inputs (000)     538 - Loss:  0.011  - Validation loss:  0.021\n",
      "Epoch  55/60 Batch     60/77 Inputs (000)     540 - Loss:  0.011  - Validation loss:  0.019\n",
      "Epoch  56/60 Batch     20/77 Inputs (000)     545 - Loss:  0.009  - Validation loss:  0.020\n",
      "Epoch  56/60 Batch     40/77 Inputs (000)     548 - Loss:  0.010  - Validation loss:  0.020\n",
      "Epoch  56/60 Batch     60/77 Inputs (000)     550 - Loss:  0.010  - Validation loss:  0.018\n",
      "Epoch  57/60 Batch     20/77 Inputs (000)     555 - Loss:  0.008  - Validation loss:  0.019\n",
      "Epoch  57/60 Batch     40/77 Inputs (000)     557 - Loss:  0.010  - Validation loss:  0.019\n",
      "Epoch  57/60 Batch     60/77 Inputs (000)     560 - Loss:  0.010  - Validation loss:  0.018\n",
      "Epoch  58/60 Batch     20/77 Inputs (000)     565 - Loss:  0.008  - Validation loss:  0.018\n",
      "Epoch  58/60 Batch     40/77 Inputs (000)     567 - Loss:  0.009  - Validation loss:  0.018\n",
      "Epoch  58/60 Batch     60/77 Inputs (000)     570 - Loss:  0.009  - Validation loss:  0.017\n",
      "Epoch  59/60 Batch     20/77 Inputs (000)     575 - Loss:  0.007  - Validation loss:  0.017\n",
      "Epoch  59/60 Batch     40/77 Inputs (000)     577 - Loss:  0.009  - Validation loss:  0.018\n",
      "Epoch  59/60 Batch     60/77 Inputs (000)     580 - Loss:  0.008  - Validation loss:  0.016\n",
      "Epoch  60/60 Batch     20/77 Inputs (000)     585 - Loss:  0.007  - Validation loss:  0.017\n",
      "Epoch  60/60 Batch     40/77 Inputs (000)     587 - Loss:  0.008  - Validation loss:  0.017\n",
      "Epoch  60/60 Batch     60/77 Inputs (000)     590 - Loss:  0.008  - Validation loss:  0.015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained in 0h:2m:4s and Saved\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Split data to training and validation sets\n",
    "train_source = source_letter_ids[batch_size:]\n",
    "train_target = target_letter_ids[batch_size:]\n",
    "valid_source = source_letter_ids[:batch_size]\n",
    "valid_target = target_letter_ids[:batch_size]\n",
    "(valid_targets_batch, valid_sources_batch, valid_targets_lengths, valid_sources_lengths) = next(get_batches(valid_target, valid_source, batch_size,\n",
    "                           source_letter_to_int['<PAD>'],\n",
    "                           target_letter_to_int['<PAD>']))\n",
    "\n",
    "#if (len(source_sentences) > 10000):\n",
    "#    display_step = 100 # Check training loss after each of this many batches with large data\n",
    "#else:\n",
    "display_step = 20 # Check training loss after each of this many batches with small data\n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    start = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    for epoch_i in range(1, epochs+1):\n",
    "        for batch_i, (targets_batch, sources_batch, targets_lengths, sources_lengths) in enumerate(\n",
    "                get_batches(train_target, train_source, batch_size,\n",
    "                           source_letter_to_int['<PAD>'],\n",
    "                           target_letter_to_int['<PAD>'])):\n",
    "            \n",
    "            # Training step\n",
    "            _, loss = sess.run(\n",
    "                [train_op, cost],\n",
    "                {input_data: sources_batch,\n",
    "                 targets: targets_batch,\n",
    "                 lr: learning_rate,\n",
    "                 target_sequence_length: targets_lengths,\n",
    "                 source_sequence_length: sources_lengths})\n",
    "\n",
    "            # Debug message updating us on the status of the training\n",
    "            if batch_i % display_step == 0 and batch_i > 0:\n",
    "                \n",
    "                # Calculate validation cost\n",
    "                validation_loss = sess.run(\n",
    "                [cost],\n",
    "                {input_data: valid_sources_batch,\n",
    "                 targets: valid_targets_batch,\n",
    "                 lr: learning_rate,\n",
    "                 target_sequence_length: valid_targets_lengths,\n",
    "                 source_sequence_length: valid_sources_lengths})\n",
    "                \n",
    "                print('Epoch {:>3}/{} Batch {:>6}/{} Inputs (000) {:>7} - Loss: {:>6.3f}  - Validation loss: {:>6.3f}'\n",
    "                      .format(epoch_i, epochs, batch_i, len(train_source) // batch_size, \n",
    "                              (((epoch_i - 1) * len(train_source)) + batch_i * batch_size) // 1000, \n",
    "                              loss, validation_loss[0]))\n",
    "\n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, checkpoint)\n",
    "    end = time.time()\n",
    "    seconds = end - start\n",
    "    m, s = divmod(seconds, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    print('Model Trained in {}h:{}m:{}s and Saved'.format(int(h), int(m), int(s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "**Start here to use a saved and pre-trained graph.** Load the saved graph and compute some preditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load source_letter_to_int from file:\n",
    "with open(SOURCE_LETTER_TO_INT, 'r') as file:\n",
    "    try:\n",
    "        source_letter_to_int = json.load(file)\n",
    "    except ValueError: # if the file is empty the ValueError will be thrown\n",
    "        data = {}\n",
    "source_letter_to_int = {k:int(v) for k,v in source_letter_to_int.items()}\n",
    "\n",
    "def source_to_seq(text):\n",
    "    '''Prepare the text for the model'''\n",
    "    sequence_length = 7\n",
    "    return [source_letter_to_int.get(word, source_letter_to_int['<UNK>']) for word in text]+ [source_letter_to_int['<PAD>']]*(sequence_length-len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded batch_size = 128\n",
      "INFO:tensorflow:Restoring parameters from ./best_model.ckpt\n",
      "Original Text: hello\n",
      "\n",
      "Source\n",
      "  Word Ids:    [19, 26, 14, 14, 17, 0, 0]\n",
      "  Input Words: h e l l o <PAD> <PAD>\n",
      "\n",
      "Target\n",
      "  Word Ids:       [26, 19, 14, 14, 17, 3]\n",
      "  Response Words: e h l l o <EOS>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "input_sentence = 'hello'\n",
    "text = source_to_seq(input_sentence)\n",
    "\n",
    "# Load source_int_to_letter and target_int_to_letter from files:\n",
    "with open(SOURCE_INT_TO_LETTER, 'r') as file:\n",
    "    try:\n",
    "        source_int_to_letter = json.load(file)\n",
    "    except ValueError: # if the file is empty the ValueError will be thrown\n",
    "        data = {}\n",
    "source_int_to_letter = {int(k):v for k,v in source_int_to_letter.items()}\n",
    "with open(TARGET_INT_TO_LETTER, 'r') as file:\n",
    "    try:\n",
    "        target_int_to_letter = json.load(file)\n",
    "    except ValueError: # if the file is empty the ValueError will be thrown\n",
    "        data = {}\n",
    "target_int_to_letter = {int(k):v for k,v in target_int_to_letter.items()}\n",
    "\n",
    "# Read batch_size from file\n",
    "with open(GRAPH_PARAMETERS, 'r') as file:\n",
    "    try:\n",
    "        batch_size = int(file.read())\n",
    "        print(\"Loaded batch_size = {}\".format(batch_size))\n",
    "    except ValueError:\n",
    "        batch_size = 128\n",
    "        print(\"Unable to load batch_size from file so using default 128.\")\n",
    "\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(checkpoint + '.meta')\n",
    "    loader.restore(sess, checkpoint)\n",
    "\n",
    "    input_data = loaded_graph.get_tensor_by_name('input:0')\n",
    "    logits = loaded_graph.get_tensor_by_name('predictions:0')\n",
    "    source_sequence_length = loaded_graph.get_tensor_by_name('source_sequence_length:0')\n",
    "    target_sequence_length = loaded_graph.get_tensor_by_name('target_sequence_length:0')\n",
    "    \n",
    "    #Multiply by batch_size to match the model's input parameters\n",
    "    answer_logits = sess.run(logits, {input_data: [text]*batch_size, \n",
    "                                      target_sequence_length: [len(text)]*batch_size, \n",
    "                                      source_sequence_length: [len(text)]*batch_size})[0] \n",
    "\n",
    "\n",
    "pad = source_letter_to_int[\"<PAD>\"] \n",
    "\n",
    "print('Original Text:', input_sentence)\n",
    "\n",
    "print('\\nSource')\n",
    "print('  Word Ids:    {}'.format([i for i in text]))\n",
    "print('  Input Words: {}'.format(\" \".join([source_int_to_letter[i] for i in text])))\n",
    "\n",
    "print('\\nTarget')\n",
    "print('  Word Ids:       {}'.format([i for i in answer_logits if i != pad]))\n",
    "print('  Response Words: {}'.format(\" \".join([target_int_to_letter[i] for i in answer_logits if i != pad])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
